이 chapter에서는 paging 기법을 사용한다고 가정한다.

# 1. Demand paging
- 실제로 필요할 때(요청이 들어올 때) page를 메모리에 올리는 것
  - I/O 양의 감소
  - Memory 사용량 감소
  - 빠른 응답 시간
  - 더 많은 사용자 수용
- Valid / Invalid bit의 사용
  - Invalid의 의미: 사용되지 않는 주소 영역이 ㄴ경우, 페이지가 물리적 메모리에 없는 경우
  - 처음에는 모든 Page entry가 invalid로 초기화
  - address translation시에 invalid bit가 set되어 있으면 page fault(요청한 page가 메모리에 없는 경우, 이 때 cpu는 자동적으로 OS에게 넘겨진다.)

# 2. Page fault
- invalid page를 접근하면 MMU가 trap을 발생시킨다. (page fault trap)
- kernel mode로 들어가서 page fault handler가 Inovke된다.
- 다음과 같은 순서로 page fault 처리
  1. Invalid reference인가? (eg. bad address, protection violation) 맞다면 abort process
  2. invalid reference가 아니라면 empty page frame을 얻는다. (없다면 뺏어온다: replace)
  3. 해당 page를 disk에서 memory로 읽어온다.
    - disk I/O가 끝날 때까지 이 process는 cpu를 preempt당함 (block 상태가 됨)
    - disk read가 끝나면 page tables entry 기록, invalid bit를 valid bit로 변경
    - ready queue에 process를 추가 -> dispatch later
  4. 이 process가 cpu를 잡고 다시 running
  5. 이전에 중단되었던 instruction 재개
- page fault 비율을 p라 하면(0: no page fault, 1: all page fault) EAT(Effective Access Time) = (1-p)*memory access + p*(OS & HW page fault overhead + swap page out if need + swap page in + OS & HW restart overhead), 즉 page fault가 발생하면 시간이 매우 오래 걸림
- Page replacement
  - frame의 여유가 없는 경우 어떤 frame을 뺏어 올 지 결정해야 한다.
  - 곧바로 사용되지 않을 page를 쫓아내는 것이 좋다.
  - 동일한 페이지가 여러 번 메모리에서 쫓겨났다가 다시 들어올 수 있다.
  - Replacement algorithm
    - page fault rate를 최소화하는 것이 목표
    - 알고리즘의 평가: 주어진 page reference string에 대해 page fault를 얼마나 내는지 조사

# 3. Replacement algorithm
### Optimal algorithm 
- 가장 먼 미래에 참조되는 page를 replace
- page string을 알고 있다고 가정(page 사용 순서를 알고 있다고 가정)
- 미래의 참조를 아는 방법: Offline algorithm
- 다른 알고리즘의 성능에 대한 upper bound 제공(다른 어떤 알고리즘을 사용해도 이 알고리즘보다 적은 수의 page fault를 낼 수는 없다.)
- Min algorithm, belays optimal algorithm, offline optimal algorithm, OPT 등으로 불린다.

### FIFO (First In First Out) algorithm
- 먼저 들어온 것을 먼저 내쫓음
- FIFO Anomaly (Belady’s Anomaly): frame 수가 늘어난다고 해서 page fault가 줄어들지는 않는다. frame을 늘렸을 때 성능이 더 안좋아질수도 있다.

### LRU (Least Recently Used) algorithm
- 가장 오래 전에 참조된 것을 지움

### LFU (Least Frequently Used) algorithm
- 참조 횟수(reference count)가 가장 적은 페이지를 지움
- 최저 참조 횟수인 page가 여럿 있는 경우 LFU 알고리즘 자체에서는 여러 page 중 임의를 선정해 지운다. 하지만 성능 향상을 위해 가장 오래 전에 참조된 page를 지우게 구현할 수도 있다.
- 장단점
  - LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에 page의 인기도를 좀 더 정확히 반영할 수 있음
  - 참조 시점의 최근성을 반영하지 못함
  - LRU보다 구현이 복잡함

### LRU와 LFU 알고리즘의 구현
- LRU
  - 가장 아래에는 최근에 사용한 Page, 가장 위에는 오래전에 사용한 page로 정렬한다. page를 지워야 할 때에는 가장 위의 page를 지우면 된다. (linkedList 형태)
  - 리스트 중간의 page가 참조된 경우 해당 page를 가장 아래로 내린다.
  - O(1) 복잡도
- LFU
  1. 가장 아래에는 참조 횟수가 많은 page, 가장 위에는 참조횟수가 적은 page로 정렬, page를 지워야 할 때는 가장 위의 page를 지운다.
    - LRU와 다르게 중간의 page를 쓴 경우 다른 page들과 참조횟수를 비교해서 다시 정렬해야 한다.
    - O(n) 복잡도
  2. heap으로 구현한다.
    - O(logn) 복잡도

### 다양한 캐슁 환경
- 캐슁 기법
  - 한정된 빠른 공간 (=cache)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식
  - paging system 외에도 cache memory, buffer caching, web caching 등 다양한 분야에서 사용
- 캐쉬 운영의 사간 제약
  - 교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우 실제 시스템에서 사용할 수 없다.
  - buffer caching이나 web caching의 경우 O(1)에서 O(logn) 정도까지 허용
  - paging system인 경우 page fault인 경우에만 OS가 관여, 페이지가 이미 메모리에 존재하는 경우 참조시각 등의 정보를 OS가 알 수 없다.(page fault가 나지 않으면 OS가 cpu를 얻지 못해 LRU, LFU에서 사용하는 linked list, heap 등을 업데이트할 수 없다.) O(1)인 LRU의 list 조작조차 불가능하다. (LRU, LFU를 사용할 수 없다.)

### Clock algorithm
- LRU의 근사(approximation) 알고리즘
- second chance algorithm, NUR(Not Used Recently), NRU(Not Recently Used) 라고도 부른다
- Reference bit를 사용해 교체 대상 페이지를 선정 (circular list, hardware가 page를 참조할 경우 page table의 reference bit을 1로 바꾼다.)
- reference bit가 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동, 이 때 만약 reference bit이 1이라면 0으로 바꾸어 준 후 포인터를 앞으로 이동한다.
- reference bit가 0인 것을 찾으면 그 page를 고체
- 한 바퀴를 돌아도(=second chance) reference bit가 0이라면(그 동안 한 번도 참조되지 않았다면) replace 당함. 자주 사용되는 page라면 한 바퀴 도는 중 reference bit가 1로 바뀔 것이다.
- clock algorithm의 개선
  - reference bit과 modified bit(=dirty bit)을 함께 사용
  - reference bit이 1이라면 최근에 참조된 page
  - modified bit가 1이라면 최근에 변경된 page (I/O를 동반하는 page)
  - modified bit가 0이라면 메모리에서 쫓아내기만 하면 되지만 1이라면 수정이 된 것이기 때문에 backing store에 수정된 내용을 적고 replace -> modified bit이 0인 것을 우선적으로 replace한다면 더 빠르다

# 4. page frame의 allocation
- allocation problem: 각 process에 얼마만큼의 page frame을 할당할 것인가?
- allocation의 필요성
  - 메모리 참조 명령어 수행시 명령어, 데이터 등 여러 페이지 동시 참조 (명령어 수행을 위해 최소한 할당되어야 하는 frame의 수가 있음)
  - Loop를 구성하는 page들은 한꺼번에 allocation되는 것이 유리함 (최소한의 allocation이 없다면 매 Loop마다 page fault가 발생할 것이다.)
- allocation scheme
  - Equal allocation: 모든 프로세스에 똑같은 frame 개수 할당
  - Proportional allocation: 프로세스의 크기에 비례해 할당
  - Priority allocation: 프로세스의 priority에 따라 다르게 할당

### Global vs Local Replacement
- Global replacement
  - replace시 다른 process에 할당된 frame을 빼앗아 올 수 있다.
  - process별 할당량을 조절하는 또 다른 방법이다.
  - FIFO, LRU, LFU 등의 알고리즘을 global replacement로 사용시에 해당한다.
  - process별로 미리 frame을 할당하지 않고 알아서 조절되게 한다.
  - Working set, PFF 알고리즘 사용
- Local replacement
  - 자신에게 할당된 frame 내에서만 replacement
  - FIFO, LRU, LFU 등의 알고리즘을 process별로 운영시 해당
  - process별로 미리 frame을 할당한다.

### Thrashing
- 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당받지 못한 경우
- page fault rate가 매우 높아지고 cpu utilization이 낮아진다.
- OS는 MPD(MultiProgramming Degree)를 높여야 한다고 판단(일반적으로 MPD가 높은 경우, 즉 cpu에 여러 프로그램이 올라가 있는 경우 cpu utilization이 높아진다)
- 또 다른 process가 시스템에 추가되고 process당 할당된 frame 수가 더 감소해 process는 page swap in/out으로 매우 바쁘며 cpu는 놀게 된다. -> low throughput

### Working set Model
- locality of reference
  - process는 특정 시간 동안 일정 장소만을 집중적으로 참조한다.
  - 집중적으로 참조되는 해당 Page들의 집합을 locality set이라 한다.
- working set model
  - locality에 기반해 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합을 working set이라 정의한다.
  - working set 모델에서는 process의 working set 전체가 메모리에 올라와 있어야 수행되고 그렇지 않을 경우 모든 frame을 반납한 후 swap out(suspend)
  - Thrashing을 방지함
  - Multiprogramming degree를 결정한다.
- working set algorithm
  - working set window를 통해 working set 결정
  - window size가 D인 경우 현재부터 D시간 전까지 참조된 페이지들의 집합을 working set으로 결정한다.
  - working set에 속한 page는 메모리에 유지, 속하지 않는 것은 버린다. (즉, 참ㅈ조된 후 D시간 동안 해당 page를 메모리에 유지한 이후 버린다.)
  - process들의 working set size의 합이 page frame의 수보다 큰 경우 일부 processfmf swap out시켜 남은 process들의 working set을 우선적으로 충족시켜 준다. (MPD를 줄인다)
  - working set을 다 할당하고도 page frame이 남는 경우 swap out되었던 process에게 working set을 할당한다. (MPD를 높인다.)
  - Window size D가 너무 작으면 locality set을 모두 수용하지 못할 수 있으며 너무 크면 여러 규모의 locality set을 수용한다. D가 infinity라면 전체 프로그램을 구성하는 page를 working set으로 간주한다.

### PFF(Page Fault Frequency) Scheme
- page fault rate의 상한값과 하한값을 둔다.
  - 어떤 process의 page fault rate가 상한값을 넘으면 해당 process에 frame을 더 할당한다.
  - page fault rate가 하한값 이하라면 할당 frame 수를 줄인다.
- 빈 frame이 없다면 일부 process를 swap out한다.

# 5. Page size의 결정
- page size를 감소시킨다면 (일반적으로 page size는 4KB)
  - page 수 증가
  - page table 크기 증가
  - internal fragmentation 감소
  - Disk transfer 효율성 감소 (disk는 seek하는 시간이 오래 걸리기 때문에 한 번에 많은 양의 정보를 transfer하는 것이 좋지만 page 크기가 작아진다면 transfer 정보량이 적어진다.)
  - 필요한 정보만 메모리에 올라가 메모리 이용이 효율적으로 됨 (But locality의 활용 측면에서는 좋지 않다.)
- 현재 trend는 page size를 키우는 것
