# 1. greedy technique
- dynamic programming과 같이 optimization problems를 푼다.
- 과거나 미래의 행동이 현재의 행동에 영향을 주지 않는다고 가정한다.
- 그리디 알고리즘은 현재 시점에서 가장 좋다고 보이는 것을 선택하는 과정을 통해 해를 구한다.
- 구한 해는 국소적으로는 최적해일 수 있지만 전체의 최적해는 아닐 수 있다.
- general guideline for a greedy algorithm
  1. A selection procedure: choose the next item to add to the set. the selection is preformed according to a greedy criterion that satisfies some locally optimal consideration at the time.
  2. A feasibility check: determines if the new set if feasible by checking whether it is possible to complete this set by adding the remaining steps. Can the partially constructed solution can be extended to get the complete solution?
  3. A solution check: determines whether the new set constitutes a solution to the instance

# 2. Minimum spanning tree(MST) 최소 신장 트리
- definitions
  - An undirected graph is called connected if there is a path between every pair of vertices
  - A simple cycle is a path from a vertex to itself with distinct intermediate vertices
  - An acyclic graph is an undirected graph with no simple cycles
  - A rooted tree is an acyclic, connected, undirected graph
  - A spanning tree of a graph G is a tree that contains all the vertices in G
  - 즉 그래프 G의 모든 노드를 포함하며 노드들이 모두 연결되어 있는 경우를 spanning tree라고 부른다. -> 노드는 모두 포함되어 있어야 하지만 간선은 모두 포함되지 않아도 되므로 하나의 그래프에는 여러 신장 트리가 존재한다.

### prim algorithm
- 노드를 중심으로 최소 신장 트리를 만든다.
- 다익스트라 알고리즘과 비슷하지만 다르다. 다익스트라 알고리즘은 해당 노드에서 다른 노드로 가는 최소 경로 찾기, 프림 알고리즘은 최소 신장 트리 만들기. 다익스트라 결과가 프림 결과와 같다는 보장이 없다. 하지만 구현 과정이 매우 비슷하긴 하다.

```swift
import Foundation

class node {
    let num: Int
    var to: [Int] = []
    
    init (num: Int, to: [Int]) {
        self.num = num
        for to in to {
            self.to.append(to)
        }
    }
}

func prim (nodes: [node], costList: [[Int]]) -> [Int] {
    var parent: [Int] = [Int] (repeating: 0, count: nodes.count) // 각 노드의 바로 위 부모 노드를 저장하는 배열
    for i in 0..<parent.count {
        parent[i] = i
    }
    
    let inf: Int = Int.max/2 - 1 // infinite를 표시하기 위한 임의의 큰 수
    let start: Int = 3 // 시작 노드, 여기선 임의로 3번째 노드라고 정했다.
    var cost: [Int] = [Int] (repeating: inf, count: nodes.count) // 각 노드의 cost?를 저장하는 배열
    var check: [Bool] = [Bool] (repeating: false, count: nodes.count) // 노드 방문 정보 저장 배열
    var queue: [node] = [] // 노드 정보를 담을 큐, cost가 가장 작은 노드가 가장 앞으로 오게 정렬할 것이다.
    queue.append(nodes[start])
    cost[start] = 0 // 시작 노드의 cost를 0으로 설정해 준다.
    
    while !queue.isEmpty {
        let node = queue.removeFirst()
        check[node.num] = true
        for to in node.to {
            if !check[to] && cost[to] > costList[node.num][to] {
                cost[to] = costList[node.num][to]
                queue.append(nodes[to])
                parent[to] = node.num
            }
        }
        queue.sort {cost[$0.num] < cost[$1.num]}
    }
    return parent
}

var nodes: [node] = []
nodes.append(node(num: 0, to: [1,3]))
nodes.append(node(num: 1, to: [0,2,3,4]))
nodes.append(node(num: 2, to: [1,4,5]))
nodes.append(node(num: 3, to: [0,1,4,6]))
nodes.append(node(num: 4, to: [1,2,3,5]))
nodes.append(node(num: 5, to: [2,4,6]))
nodes.append(node(num: 6, to: [3,5]))

let inf = Int.max/2 - 1
let costList = [[inf, 10, inf, 5, inf, inf, inf],
                [10, inf, 2, 7, 12, inf, inf],
                [inf, 2, inf, inf, 11, 14, inf],
                [5, 7, inf, inf, 6, inf, 9],
                [inf, 12, 11, 6, inf, 15, inf],
                [inf, inf, 14, inf, 15, inf, 3],
                [inf, inf, inf, 9, inf, 3, inf]]

print(prim(nodes: nodes, costList: costList))
```

- 위와 같이 구현할 경우 O(n^2)으로 매우 오래 걸린다. 우선순위 큐를 이용할 경우 O(n*log n)으로 시간을 줄일 수 있으며 이는 다익스트라 또한 마찬가지다.

### kruskal algorithm
- 간선을 중심으로 최소 신장 트리를 만든다.
```swift
import Foundation

class edge {
    let from: Int
    let to: Int
    let cost: Int
    
    init (from: Int, to: Int, cost: Int) {
        self.from = from
        self.to = to
        self.cost = cost
    }
}

// 부모 노드를 찾는다.
func findParent (arr: [Int], x: Int) -> Int {
    if arr[x] == x {
        return x
    }
    
    return findParent(arr: arr, x: arr[x])
}

// a와 b 노드를 잇는다(같은 부모를 가지게 한다)
func unionParent (arr: inout [Int], a: Int, b: Int) {
    let aa = findParent(arr: arr, x: a)
    let bb = findParent(arr: arr, x: b)
    
    if aa < bb {
        arr[bb] = aa
    } else {
        arr[aa] = bb
    }
}

// 같은 그래프에 속하는지(부모가 같은지) 확인한다
func findParent (arr: [Int], a: Int, b: Int) -> Bool {
    let aa = findParent(arr: arr, x: a)
    let bb = findParent(arr: arr, x: b)
    
    if aa == bb {
        return true
    } else {
        return false
    }
}

func kruskal (edges: [edge]) {
    var edges = edges
    edges.sort { $0.cost < $1.cost} // cost가 낮은 것이 앞으로 오게 정렬
    // 각 노드의 부모 노드 정보를 담고 있는 배열을 만든다
    var parent: [Int] = [Int] (repeating: 0, count: nodes.count)
    for i in 0..<parent.count {
        parent[i] = i
    }
    
    for i in 0..<edges.count {
        let edge: edge = edges[i]
        if !findParent(arr: parent, a: node.from, b: node.to) { // 동일한 부모를 가지고 있는 노드를 연결할 경우 사이클이 생긴다.
            unionParent(arr: &parent, a: node.from, b: node.to) // 부모가 다른 경우 둘을 이어 준다.
        }
    }
}
```

- 노드 수를 n, 간선 수를 m이라 하면 간선들을 최소 거리 기준으로 정렬하는대 O(m*log m), parent 배열 초기화에 O(n), findParent는 최악의 경우 O(m)의 시간복잡도를 가지므로 마지막 for문은 O(m*log m), 간선이 가장 많을 때 m= n(n+1)/2이므로 크루스칼 알고리즘의 사간복잡도는 (n^2 * log n)이다.

# 3. shortest path from single source to many destinations
- floyd warshall 알고리즘은 모든 노드에서 다른 모든 노드로의 최단경로를 구했지만 한 노드에서의 최단경로만 알고 싶은 경우 floyd는 시간이 너무 오래 걸린다.

```swift
import Foundation

// 주어진 cost 배열에서 방문하지 않은(=check가 false인) 가장 작은 값이 있는 index 반환
func findMin (check: [Bool], cost: [Int]) -> Int {
    var min: Int = Int.max
    var index: Int = 0
    
    for i in 0..<cost.count {
        if cost[i] < min && !check[i] {
            index = i
            min = cost[i]
        }
    }
    
    return index
}

func dijk (costList: [[Int]], startNode: Int) -> [Int] {
    var cost: [Int] =  costList[startNode]// 해당 노드에서 다른 노드까지의 거리를 저장할 배열, 반환할 배열이다.
    var check: [Bool] = [Bool] (repeating: false, count: cost.count) // 해당 노드를 방문했는지 기록할 배열
    check[startNode] = true
        
    for _ in 0..<costList.count-1 {
        let current: Int = findMin(check: check, cost: cost)
        check[current] = true // 이전 위치에서 가장 적은 비용으로 이동할 수 있는 곳을 current로 잡는다.
        
        for i in 0..<cost.count {
            if !check[i] && cost[i] > cost[current] + costList[current][i] { // current를 거쳐서 j로 가는 비용이 원래 j로 가는 비용보다 싼 경우
                cost[i] = cost[current] + costList[current][i] // 최솟값을 갱신해 준다
            }
        }
    }

    return cost
}

let inf: Int = Int.max - 10000
var a: [[Int]] = [[0,2,5,1,inf,inf],
                  [2,0,3,2,inf,inf],
                  [5,3,0,3,1,5],
                  [1,2,3,0,1,inf],
                  [inf,inf,1,1,0,2],
                  [inf,inf,5,inf,2,0]]

print(dijk(costList: a, startNode: 0))
```

- prim algorithm과 마찬가지로 위와 같이 코딩할 경우 O(n^2), 우선순위 큐를 이용할 경우 O(n*log n)의 시간이 걸린다.

# 4. Huffman code
- 문자를 bit으로 치환할 때 각 문자가 같은 bit으로 이루어져 있지 않고 다르다면 (eg. 0001, 0010과 같이 자리수가 4로 정해져 있지 않고 a: 1, b: 101과 같이 문자마다 자리수가 다른 경우) prefix-free code를 통해 디코딩을 할 수 있다.
  - 한 문자의 code는 다른 문자의 시작 code가 될 수 없다. (eg. a: 10이라면 다른 문자는 101, 1011과 같이 10으로 시작하는 code를 가질 수 없다)
  - 모든 prefix-free code는 binary tree data structure로 구조화할 수 있다.
  - 파일의 첫 번째 bit가 tree의 root가 되게 하고 다음 문자부터 0이면 왼쪽, 1이면 오른쪽으로 내려가는 등의 방법으로 탐색할 수 있다.
  - 만약 도착한 leaf가 치환할 문자(a와 같은)일 경우 지금까지의 bit를 해당 문자로 치환하고 다음 bit을 root로 가지는 트리로 이동해 과정을 반복한다.
- 후프만 코드는 문장에서 자주 등장하는 기호들은 짧은 비트자리수를 가지게, 잘 등장하지 않는 기호들은 긴 비트자리수를 가지게 한다.
- 다음 bit가 0인 경우 왼쪽 간선을 통해 왼쪽으로, 1인 경우 오른쪽으로 내려간다.
- n 문자를 인코딩하는 후프만 알고리즘
  1. initialization step: n개의 트리를 만든다. 각 트리는 단 1개의 노드를 가지며 그 노드는 주어진 n개의 문자들을 나타낸다. 각 트리의 root에 해당 문자의 빈도수를 기록한다.(이 숫자는 각 트리의 weight를 나타내게 된다.)
  2. 아래의 과정을 n-1번 반복해 n개의 트리를 1개로 만든다.
    - 1에서 구한 root의 weight가 가장 작은 2개의 트리를 합친다. 새로운 트리의 root의 weight는 합친 두 트리 weight의 합이 되며 root 왼쪽의 트리로 이어지는 간선은 0으로, 오른쪽 트리로 이어지는 간선은 1로 라벨링한다.
- compression efficiency: fixed-length code보다 후프만 코드가 메모리를 덜 사용하는 정도
  1. number of bits per character 계산: 해당 문자가 나올 확률 * 깊이(코드로 나타냈을 때 자릿수, 101이라면 3, 11이라면 2 등)를 모든 문자에 대해 구한 후 더한 것
  2. bits per symbol by fixed: 고정된 자리수의 bit로 바꾸었을 때 필요한 bit, 후프만 코드를 사용했을 때 가장 큰 자리수의 bit과 동일하다. (eg. 10, 111, 101, 0이 후프만 코드의 결과라면 고정된 bit수를 사용할 경우 3이 필요하다.)
  3. compression efficiency = (no.2 - no.1) / (no.2) * 100   (number of bits per character = 2.25, bits per symbol by fixed=3이라면 압축효율 = 100*(3-2.25)/3=25%)

# 5. Greedy vs Dynamic programming
- shortest paths from many sources to many destinations problem의 경우
  - dynamic programming algorithm으로 풀 수 있다. -> Floyd algorithm, 시간복잡도는 O(n^3)
- shortest paths from one source to many destinations problem의 경우
  - dynamic programming으로 풀 경우 floyd algorithm을 사용해야 하며 O(n^3)
  - greedy algorithm으로 풀 경우 dijkstra algorithm을 사용하면 되며 시간복잡도는 O(n^2)에서 구현에 따라 O(n*log n)까지 줄일 수 있다. -> 더 효율적이다.
- zero-one knapsack problem의 경우
  - greedy algorithm으로는 최적해를 구할 수 없다.(만약 1-0문제가 아니라 분할 가능할 경우 greedy algorithm으로 최적해를 구할 수 있다.)
  - 반면 dynamic programming을 통해선 최적해를 구할 수 있다.

# 6. Memory function: Hybrid approach
- recurrence 관계가 성립하는 문제에서 같은 문제를 푸는 것이 반복될 경우 
  - recursive solution(direct top-down approach)는 같은 문제를 여러 번 풀기 때문에 느리다.
  - dynamic programming approach(bottom-up)은 한 번 수행한 계산은 다시 하지 않기 때문에 빠르다. 하지만 작은 부분으로 쪼개진 문제 중 일부는 원래 문제를 푸는 데 필요가 없는 경우도 존재한다.
- dynamic programming과 같이 별도의 table을 통해 값을 저장해 같은 계산은 한 번만 수행하지만 bottom-up이 아니라 top-down 방식으로 진행하면 두 방법의 장점을 모두 취할 수 ㅣㅇㅆ다.
